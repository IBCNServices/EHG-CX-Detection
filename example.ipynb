{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:105: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from cx_model import CXDetector\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import wfdb\n",
    "from scipy.signal import butter, lfilter, medfilt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def _read_signal(file, low_freq, high_freq, sample_freq):\n",
    "    record = wfdb.rdrecord(file)\n",
    "    annotation = wfdb.rdann(file, 'atr')\n",
    "    annotated_intervals = list(zip(annotation.sample, annotation.aux_note))\n",
    "    \n",
    "    signal_ch1 = record.p_signal[:, 0][1500:-1500]\n",
    "    signal_ch2 = record.p_signal[:, 2][1500:-1500]\n",
    "    signal_ch3 = record.p_signal[:, 4][1500:-1500]\n",
    "    \n",
    "    signal_ch1 = butter_bandpass_filter(signal_ch1, low_freq, \n",
    "                                        high_freq, sample_freq, order=4)\n",
    "    signal_ch2 = butter_bandpass_filter(signal_ch2, low_freq, \n",
    "                                        high_freq, sample_freq, order=4)\n",
    "    signal_ch3 = butter_bandpass_filter(signal_ch3, low_freq, \n",
    "                                        high_freq, sample_freq, order=4)\n",
    "    \n",
    "    for i, ann in enumerate(annotated_intervals):\n",
    "        annotated_intervals[i] = (ann[0] - 1500, ann[1]) \n",
    "\n",
    "    signal_ch1 = medfilt(signal_ch1)\n",
    "    signal_ch2 = medfilt(signal_ch2)\n",
    "    signal_ch3 = medfilt(signal_ch3)\n",
    "\n",
    "    ch1_scaler = RobustScaler()\n",
    "    ch2_scaler = RobustScaler()\n",
    "    ch3_scaler = RobustScaler()\n",
    "\n",
    "    signal_ch1 = ch1_scaler.fit_transform(signal_ch1.reshape(-1, 1)).reshape(-1, )\n",
    "    signal_ch2 = ch2_scaler.fit_transform(signal_ch2.reshape(-1, 1)).reshape(-1, )\n",
    "    signal_ch3 = ch3_scaler.fit_transform(signal_ch3.reshape(-1, 1)).reshape(-1, )\n",
    "        \n",
    "    return signal_ch1, signal_ch2, signal_ch3, annotated_intervals\n",
    "\n",
    "\n",
    "def _read_clinical(file):\n",
    "    start_idx = 0\n",
    "    with open(file+'.hea', 'r') as ifp:\n",
    "        lines = ifp.readlines()\n",
    "        \n",
    "    for line_idx, line in enumerate(lines):\n",
    "        if line.startswith('#'):\n",
    "            start_idx = line_idx\n",
    "            break\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "    for line in lines[start_idx+1:]:\n",
    "        _, name, value = line.split()\n",
    "        names.append(name)\n",
    "        values.append(value)\n",
    "\n",
    "    return names, values\n",
    "\n",
    "def _process_clinical_df(clin_df):\n",
    "    clin_df = clin_df.drop(['Gestation'], axis=1)\n",
    "    clin_df = clin_df.replace('None', np.NaN)\n",
    "    clin_df = clin_df.replace('N/A', np.NaN)\n",
    "    clin_df['ID'] = clin_df['RecID']\n",
    "    for col in ['Rectime', 'Age', 'Abortions', 'Weight']:\n",
    "        clin_df[col] = clin_df[col].astype(float)\n",
    "    clin_df = clin_df.drop_duplicates()\n",
    "    clin_df = clin_df[['file', 'Rectime', 'Age', 'Parity', 'Abortions']]\n",
    "    return clin_df\n",
    "\n",
    "\n",
    "def partition_data(directory, n_splits=5):\n",
    "    files = np.unique([x.split('.')[0] for x in os.listdir(directory)])\n",
    "    p_files, t_files, n_files = [], [], []\n",
    "    for file in files:\n",
    "        if file[-4] == 'n':\n",
    "            n_files.append(file)\n",
    "        elif file[-4] == 'p':\n",
    "            p_files.append(file)\n",
    "        else:\n",
    "            t_files.append(file)\n",
    "\n",
    "    np.random.shuffle(p_files)\n",
    "    np.random.shuffle(t_files)\n",
    "\n",
    "    folds = []\n",
    "    for split in range(n_splits):\n",
    "        start = lambda x: int(x * (split / n_splits))\n",
    "        end   = lambda x: int(x * ((split + 1) / n_splits))\n",
    "        if split == n_splits - 1:\n",
    "            test_p_files = p_files[start(len(p_files)):]\n",
    "            test_t_files = t_files[start(len(t_files)):]\n",
    "        else:\n",
    "            test_p_files = p_files[start(len(p_files)):end(len(p_files))]\n",
    "            test_t_files = t_files[start(len(t_files)):end(len(t_files))]\n",
    "\n",
    "        train_p_files = sorted(list(set(p_files) - set(test_p_files)))\n",
    "        train_t_files = sorted(list(set(t_files) - set(test_t_files)))\n",
    "\n",
    "        test_files = test_t_files + test_p_files\n",
    "        train_files = train_t_files + train_p_files\n",
    "\n",
    "        folds.append((['{}{}{}'.format(directory, os.sep, x) for x in train_files], \n",
    "                      ['{}{}{}'.format(directory, os.sep, x) for x in test_files]))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2315, 100)\n",
      "it\t\tavg\t\tstd\t\tmax\t\ttime\n",
      "1\t\t0.2731\t\t0.025\t\t0.297963\t47.5285\n",
      "2\t\t0.2904\t\t0.007\t\t0.298383\t42.9142\n",
      "3\t\t0.295\t\t0.005\t\t0.298636\t78.2362\n",
      "4\t\t0.2986\t\t0.002\t\t0.300152\t62.9635\n"
     ]
    }
   ],
   "source": [
    "folds = partition_data('tpehgts')\n",
    "train_files, test_files = folds[0]\n",
    "detector = CXDetector(20, 0.05, 4.0, 750, 125, 100, 100, _read_signal, _read_clinical, _process_clinical_df)\n",
    "features = detector.fit(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(features.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_labels_preds(intervals, predictions):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for (start_idx, start_type), (end_idx, end_type) in zip(intervals[::2], intervals[1::2]):\n",
    "        if start_idx < 0 or end_idx >= len(predictions):\n",
    "            continue\n",
    "        if start_type[-1] == 'C':\n",
    "            labels.extend([1]*(end_idx - start_idx))\n",
    "            preds.extend(predictions.loc[list(range(start_idx, end_idx)), 'pred'].values)\n",
    "        else:\n",
    "            labels.extend([0]*(end_idx - start_idx))\n",
    "            preds.extend(predictions.loc[list(range(start_idx, end_idx)), 'pred'].values)\n",
    "\n",
    "    return labels, preds\n",
    "\n",
    "def _load_pred_labels_intervals(predictions):\n",
    "    _, _, _, intervals = _read_signal(predictions['file'].values[0], 0.05, 4.0, 20.0)\n",
    "    labels, preds = get_labels_preds(intervals, predictions)\n",
    "    return labels, preds, intervals\n",
    "\n",
    "def unweighted_auc(predictions):\n",
    "    all_labels, all_preds = [], []\n",
    "    for file in np.unique(predictions['file']):\n",
    "        preds = predictions[predictions['file'] == file].set_index('index', drop=True)\n",
    "        labels, preds, intervals = _load_pred_labels_intervals(preds)\n",
    "        all_labels.extend(labels)\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "    mask = ~np.isnan(all_preds)\n",
    "    return roc_auc_score(np.array(all_labels)[mask], np.array(all_preds)[mask])\n",
    "\n",
    "def create_plots(predictions):\n",
    "    def create_plot(signal_ch1, signal_ch2, signal_ch3, predictions, intervals):\n",
    "        f, ax = plt.subplots(4, 1, sharex=True, figsize=(15,3))\n",
    "        ax[0].plot(signal_ch1)\n",
    "        ax[1].plot(signal_ch2)\n",
    "        ax[2].plot(signal_ch3)\n",
    "\n",
    "        _max = np.max([np.max(signal_ch1), np.max(signal_ch2), np.max(signal_ch3)])\n",
    "        _min = np.min([np.min(signal_ch1), np.min(signal_ch2), np.min(signal_ch3)])\n",
    "\n",
    "        for (start_idx, start_type), (end_idx, end_type) in zip(intervals[::2], intervals[1::2]):\n",
    "            if start_type[-1] == 'C':\n",
    "                color = 'g'\n",
    "            elif start_type == '(c)':\n",
    "                color = 'y'\n",
    "            else:\n",
    "                color = 'r'\n",
    "\n",
    "            for k in range(3):\n",
    "                rect = patches.Rectangle((start_idx, _min), end_idx - start_idx, _max - _min, facecolor=color, alpha=0.5)\n",
    "                ax[k].add_patch(rect)\n",
    "\n",
    "        ax[3].plot(predictions)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    for file in np.unique(predictions['file']):\n",
    "        sign_ch1, sign_ch2, sign_ch3, intervals = _read_signal(file, 0.05, 4.0, 20.0)\n",
    "        create_plot(sign_ch1, sign_ch2, sign_ch3, predictions[predictions['file'] == file]['pred'].values, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detector.predict(test_files)\n",
    "print(unweighted_auc(preds))\n",
    "create_plots(preds) #0.8077784799594918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "def generate_predictions(file, X, idx, model, WINDOW_SIZE, DATA_DIR, OUTPUT_DIR):\n",
    "    for col in ['ID', 'file']:\n",
    "        if col in X.columns:\n",
    "            X = X.drop(col, axis=1)\n",
    "\n",
    "    signal_ch1, signal_ch2, signal_ch3, annotated_intervals = read_signal(DATA_DIR + '/' + file)\n",
    "    ts_predictions = np.empty((len(signal_ch1),), dtype=object)\n",
    "    predictions = model.predict_proba(X)[:, 1]\n",
    "    for pred, x in zip(predictions, idx):\n",
    "      for i in range(x, x+WINDOW_SIZE):\n",
    "        if ts_predictions[i] is None:\n",
    "          ts_predictions[i] = [pred]\n",
    "        else:\n",
    "          ts_predictions[i].append(pred)\n",
    "    \n",
    "    for i in range(len(signal_ch1)):\n",
    "      if ts_predictions[i] is None:\n",
    "        ts_predictions[i] = last_value\n",
    "      else:\n",
    "        avg = np.mean(ts_predictions[i])\n",
    "        ts_predictions[i] = avg\n",
    "        last_value = avg\n",
    "\n",
    "    pd.Series(ts_predictions).to_csv('{}/{}.csv'.format(OUTPUT_DIR, file))\n",
    "    create_plot(signal_ch1, signal_ch2, signal_ch3, ts_predictions, annotated_intervals, '{}/{}.png'.format(OUTPUT_DIR, file))\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
